---
title: "Data Appendix to \"Name of your paper\""
author: "Iris Zhong"
output: 
  pdf_document:
    toc: true
    number_sections: true
---

```{r setup, echo = F, message = F}
knitr::opts_chunk$set(results = 'asis', cache = F)
library(tidyverse)
library(summarytools)
library(sf)
st_options(plain.ascii = F,
           style = "rmarkdown",
           footnote = NA,
           subtitle.emphasis = F,
           dfSummary.silent = T,
           dfSummary.valid.col = F,
           tmp.img.dir = "./tmp",
           dfSummary.style = "grid")

#The following custom function simplifies the process of writing dfSummaries to html files
export_summary_table <- function(dfSummary_output){
  data_info <- attr(dfSummary_output, "data_info")
  ds_name <- data_info$Data.frame
  print(dfSummary_output,
      file = str_c("output/", ds_name, "_summary.html"),
      method = "browser",
      report.title = ds_name)
}
```

```{r set dfSummary css style, echo = F, include = F}
st_css()
```


# Raw data
*Each dataset you use will have its own documentation section. The next subsection in this document (Dataset description) is a template. You can copy this section and paste it into your document each time you need to add a section for a new dataset. Note that each line in the Dataset description section __must__ end with two spaces.* 
This section documents the datasets used in this analysis.

## Gwinnett County 2019 Referendum Dataset
**Citation:** Results—Gwinnett—Election Night Reporting. (n.d.). Retrieved March 11, 2020, from https://results.enr.clarityelections.com/GA/Gwinnett/94961/Web02.225391/#/
  
**DOI:** N/A  
**Date Downloaded:** Mar 11, 2020  
**Filename(s):** raw_data/vote_result.xls *If you have a large number of files you can use a patten (see visit data below)*
**Unit of observation:** Precinct 
**Dates covered:** Mar 19, 2019

### To obtain a copy

Users can visit the website that displays election results at Gwinnett County at https://results.enr.clarityelections.com/GA/Gwinnett/94961/Web02.225391/#/ and choose the **Detail XLS** link at the bottom right corner. 

The xls file contains three spreadsheets. What I will be using is the third sheet. 

### Importable version

**Filename(s):** importable_data/vote_result_importable.xls

The raw dataset is hard to be imported to R directly because of the following reasons. First, it has three tabs. Second, the top two rows do not contain any useful information or should be incorporated to the next row. Therefore, an importable version of the dataset was created.

Here are the steps:

1. The original file was opened in Microsoft Excel.  
2. The first and the second spreadsheets were removed. 
3. Columns H through AI (RecreationVisits through MiscellaneousOvernightStaysTotal) were highlighted and
formatted as numbers with no decimal places and no 1000 separators.  
4. The file was saved using the CSV(comma delimited) format in the importable_data folder.  

*Note:* This procedure violates one of my principles of data analysis: avoid doing the same thing over and over again. It's usually possible to get the computer to do it for you. In this case, we could get R to read in the original files directly by specifying column types and defining a special function to read-in the data. I did not do this in the demonstration file for two reasons:

1. To demonstrate how to document the process if you have to modify your raw files before importing.  
1. Because there are only a couple files, it may be faster to make this change manually than to figure out the code needed to automate it. Whether this is true or not depends on the number of files you need to modify, the likelihood that you'll have to redo it (e.g. if you decided to add years to your analysis later), and your experience with writing code. Check with me if you find yourself wondering whether you should automate something or do it manually (or see [this xkcd comic](https://imgs.xkcd.com/comics/is_it_worth_the_time_2x.png))


### Variable descriptions

Create a bullet list with the name of each variable in the dataset followed by any information the user would need to understand it.

- **variable_name:** Variable description. 
- **variable_name2:** Description of second variable.

### Data import code and summary

*Once you've described the variables, enter an R chunk by selecting Code -> Insert Chunk, or Ctrl+Alt+I, give it a name to describe the dataset you are importing. After importing, export a dataframe summary using the command.*

`export_summary_table(dfSummary(dataset_name))`

*While it will make your resulting file long, you should not modify the chunk options to suppress printing of code and output. I would likely not include this in the documentation for an actual paper I was submitting, but including them here will let me read your code and the output message from R and may help identify data import concerns early in the process. Since these files will exist only electronically, their length is less of a concern. If you like to print out files to proofread and want me to help you shorten the printed versions, let me know. We can temporarily modify the chunk options for printing and restore them before you submit the assignment.*


# Data Processing and Combination
*This section should include a discussion of the processing and merging steps needed to create your basic data. The code to implement these steps should be included in chunks in this section. Once the final merged data has been created, you should use the dfSummary function again to summarize the data you will be using. You should also save a file containing all the objects you will use in your final analysis to the processed_data folder.*

# Analysis Variables

This section should include a description of all the variables that are used in your final analysis. At the end of the section, you should save all of these variables in the processed_data folder of your repository.

# Discussion of Data

*This section should include a discussion of any data patterns you notice based on the summaries created in the code above.*
