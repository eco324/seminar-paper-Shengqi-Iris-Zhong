---
title: "Data Appendix to \"Name of your paper\""
author: "Iris Zhong"
output: 
  pdf_document:
    toc: true
    number_sections: true
---

```{r setup, echo = F, message = F}
knitr::opts_chunk$set(results = 'asis', cache = F)
library(tidyverse)
library(summarytools)
library(sf)
st_options(plain.ascii = F,
           style = "rmarkdown",
           footnote = NA,
           subtitle.emphasis = F,
           dfSummary.silent = T,
           dfSummary.valid.col = F,
           tmp.img.dir = "./tmp",
           dfSummary.style = "grid")

#The following custom function simplifies the process of writing dfSummaries to html files
export_summary_table <- function(dfSummary_output){
  data_info <- attr(dfSummary_output, "data_info")
  ds_name <- data_info$Data.frame
  print(dfSummary_output,
      file = str_c("output/", ds_name, "_summary.html"),
      method = "browser",
      report.title = ds_name)
}
```

```{r set dfSummary css style, echo = F, include = F}
st_css()
```


# Raw data
*Each dataset you use will have its own documentation section. The next subsection in this document (Dataset description) is a template. You can copy this section and paste it into your document each time you need to add a section for a new dataset. Note that each line in the Dataset description section __must__ end with two spaces.* 
This section documents the datasets used in this analysis.

## Gwinnett County 2019 Referendum Dataset
**Citation:** Results—Gwinnett—Election Night Reporting. (n.d.). Retrieved March 11, 2020, from https://results.enr.clarityelections.com/GA/Gwinnett/94961/Web02.225391/#/
  
**DOI:** N/A  
**Date Downloaded:** Mar 11, 2020  
**Filename(s):** raw_data/vote_result.xls *If you have a large number of files you can use a patten (see visit data below)*
**Unit of observation:** Precinct 
**Dates covered:** Mar 19, 2019

### To obtain a copy

Describe in a step-by-step fashion how an interested user could obtain the data.

### Importable version (if necessary)

**Filename(s):** importable-data/filename-importable.csv

In some cases the raw data is not directly importable. In this case, you should fully document every step you took to create the importable data in a subsection like this one. 

### Variable descriptions

Create a bullet list with the name of each variable in the dataset followed by any information the user would need to understand it.

- **variable_name:** Variable description. 
- **variable_name2:** Description of second variable.

### Data import code and summary

*Once you've described the variables, enter an R chunk by selecting Code -> Insert Chunk, or Ctrl+Alt+I, give it a name to describe the dataset you are importing. After importing, export a dataframe summary using the command.*

`export_summary_table(dfSummary(dataset_name))`

*While it will make your resulting file long, you should not modify the chunk options to suppress printing of code and output. I would likely not include this in the documentation for an actual paper I was submitting, but including them here will let me read your code and the output message from R and may help identify data import concerns early in the process. Since these files will exist only electronically, their length is less of a concern. If you like to print out files to proofread and want me to help you shorten the printed versions, let me know. We can temporarily modify the chunk options for printing and restore them before you submit the assignment.*


# Data Processing and Combination
*This section should include a discussion of the processing and merging steps needed to create your basic data. The code to implement these steps should be included in chunks in this section. Once the final merged data has been created, you should use the dfSummary function again to summarize the data you will be using. You should also save a file containing all the objects you will use in your final analysis to the processed_data folder.*

# Analysis Variables

This section should include a description of all the variables that are used in your final analysis. At the end of the section, you should save all of these variables in the processed_data folder of your repository.

# Discussion of Data

*This section should include a discussion of any data patterns you notice based on the summaries created in the code above.*
